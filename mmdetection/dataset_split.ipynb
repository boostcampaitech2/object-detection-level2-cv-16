{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "with open(\"../dataset/train.json\", \"r\") as f:\n",
    "    train = json.load(f)\n",
    "split_train = copy(train)\n",
    "split_valid = copy(train)\n",
    "df = pd.DataFrame(train['annotations'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257301.66</td>\n",
       "      <td>[197.6, 193.7, 547.8, 469.7]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10402.56</td>\n",
       "      <td>[0.0, 407.4, 57.6, 180.6]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26259.36</td>\n",
       "      <td>[0.0, 455.6, 144.6, 181.6]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>69096.17</td>\n",
       "      <td>[722.3, 313.4, 274.3, 251.9]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24164.58</td>\n",
       "      <td>[353.2, 671.0, 233.7, 103.4]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>188324.40</td>\n",
       "      <td>[3.7, 448.5, 778.2, 242.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38908.72</td>\n",
       "      <td>[425.3, 681.9, 216.4, 179.8]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7391.52</td>\n",
       "      <td>[92.4, 601.7, 139.2, 53.1]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6857.76</td>\n",
       "      <td>[622.4, 686.5, 72.8, 94.2]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>324010.80</td>\n",
       "      <td>[267.9, 165.2, 631.6, 513.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  category_id       area                          bbox  iscrowd  id\n",
       "0         0            0  257301.66  [197.6, 193.7, 547.8, 469.7]        0   0\n",
       "1         1            3   10402.56     [0.0, 407.4, 57.6, 180.6]        0   1\n",
       "2         1            7   26259.36    [0.0, 455.6, 144.6, 181.6]        0   2\n",
       "3         1            4   69096.17  [722.3, 313.4, 274.3, 251.9]        0   3\n",
       "4         1            5   24164.58  [353.2, 671.0, 233.7, 103.4]        0   4\n",
       "5         1            5  188324.40    [3.7, 448.5, 778.2, 242.0]        0   5\n",
       "6         1            0   38908.72  [425.3, 681.9, 216.4, 179.8]        0   6\n",
       "7         1            7    7391.52    [92.4, 601.7, 139.2, 53.1]        0   7\n",
       "8         1            0    6857.76    [622.4, 686.5, 72.8, 94.2]        0   8\n",
       "9         2            3  324010.80  [267.9, 165.2, 631.6, 513.0]        0   9"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class_per_image = [(j, [0 for i in range(10)]) for j in range(4883)]\n",
    "def clean(x):\n",
    "    '''\n",
    "    for apply : \n",
    "    '''\n",
    "    class_per_image[x['image_id']][1][x['category_id']] += 1\n",
    "df.apply(clean, axis=1)\n",
    "class_per_image = np.array(class_per_image)\n",
    "\n",
    "np.random.seed(2021)\n",
    "np.random.shuffle(class_per_image)\n",
    "class_per_image"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2826, list([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])],\n",
       "       [3835, list([0, 1, 0, 0, 0, 0, 6, 3, 0, 0])],\n",
       "       [1789, list([0, 2, 0, 0, 0, 0, 1, 5, 0, 0])],\n",
       "       ...,\n",
       "       [1152, list([1, 8, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [3413, list([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [1140, list([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_classes = np.zeros((10))\n",
    "train_indices = []\n",
    "valid_classes = np.zeros((10))\n",
    "valid_indices = []\n",
    "\n",
    "ratio = 0.2\n",
    "for image_id, classes in (class_per_image):\n",
    "    train_if_train = train_classes + classes\n",
    "    valid_if_train = valid_classes / ratio\n",
    "    mse_if_train = ((train_if_train - valid_if_train)**2).mean(axis=0)\n",
    "    \n",
    "    train_if_valid = train_classes\n",
    "    valid_if_valid = (valid_classes + classes) / ratio\n",
    "    mse_if_valid = ((train_if_valid - valid_if_valid)**2).mean(axis=0)\n",
    "\n",
    "    ### Random Forcing\n",
    "    if(np.random.random() < 0.15):\n",
    "        '''\n",
    "        Random Forcing이 없으면 한 image 안에 객체가 많을 경우 \n",
    "        Validation set으로 넣어버리면 mse가 갑자기 높아지기 때문에\n",
    "        그냥 train set으로 분류해버리는 경향이 있음\n",
    "        '''\n",
    "        valid_indices.append(int(image_id))\n",
    "        valid_classes += classes\n",
    "        continue\n",
    "    \n",
    "    if mse_if_train < mse_if_valid:\n",
    "        train_indices.append(int(image_id))\n",
    "        train_classes += classes\n",
    "    else:\n",
    "        valid_indices.append(int(image_id))\n",
    "        valid_classes += classes\n",
    "\n",
    "print(\"Train images :\" , len(train_indices))\n",
    "print(\"Validation images :\" , len(valid_indices))\n",
    "print('-'*60)\n",
    "print(\"Distribution of classes in Train dataset\")\n",
    "print(train_classes)\n",
    "print('-'*60)\n",
    "print(\"Distribution of classes in Validation dataset\")\n",
    "print(valid_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train images : 3812\n",
      "Validation images : 1071\n",
      "------------------------------------------------------------\n",
      "Distribution of classes in Train dataset\n",
      "[3305. 5193.  747.  744.  757. 2405. 1002. 4312.  125.  389.]\n",
      "------------------------------------------------------------\n",
      "Distribution of classes in Validation dataset\n",
      "[ 661. 1159.  150.  192.  225.  538.  261.  866.   34.   79.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# train, valid에 해당하는 image/annotation을 각각 저장\n",
    "train_images = []\n",
    "train_ann = []\n",
    "valid_images = []\n",
    "valid_ann = []\n",
    "for image in split_train['images']:\n",
    "    if image['id'] in train_indices:\n",
    "        train_images.append(image)\n",
    "    else:\n",
    "        valid_images.append(image)\n",
    "for ann in split_train['annotations']:\n",
    "    if ann['image_id'] in train_indices:\n",
    "        train_ann.append(ann)\n",
    "    else:\n",
    "        valid_ann.append(ann)\n",
    "split_train['images'] = train_images\n",
    "split_train['annotations'] = train_ann\n",
    "split_valid['images'] = valid_images\n",
    "split_valid['annotations'] = valid_ann\n",
    "\n",
    "len(split_train['images']), len(split_valid['images'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3812, 1071)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Save\n",
    "with open(\"../dataset/split_train_v2.json\", \"w\") as f:\n",
    "    json.dump(split_train, f)\n",
    "with open(\"../dataset/split_valid_v2.json\", \"w\") as f:\n",
    "    json.dump(split_valid, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('detection': conda)"
  },
  "interpreter": {
   "hash": "29b0cbc8c2bc4924fb253dd9334aba0cc9ad3225fd824ea55dea16089b664698"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}